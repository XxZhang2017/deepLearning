{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "INIT_LR = 5e-3\n",
    "COLORS = 1\n",
    "KERN = 3\n",
    "\n",
    "#create an object of the sequential class\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (KERN, KERN), input_shape = (64, 64, COLORS)))\n",
    "#add the pooling layer\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides= (2,2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (KERN, KERN)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Conv2D(64, (KERN, KERN), activation='relu'))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#convert the pooled images into a 1D features vector\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#initilize output layer\n",
    "model.add(Dense(6, activation = 'softmax')) #6 labels\n",
    "\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "#opt = 'adam'\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4872 images belonging to 6 classes.\n",
      "Found 659 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_datagen = ImageDataGenerator( #rescale = 1./255 \n",
    "featurewise_center=False, # set input mean to 0 over the dataset\n",
    "samplewise_center=False, # set each sample mean to 0\n",
    "featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "samplewise_std_normalization=False, # divide each input by its std\n",
    "#zca_whitening=False, # apply ZCA whitening\n",
    "rotation_range=1, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n",
    "horizontal_flip=False, # randomly flip images\n",
    "vertical_flip=False) # randomly flip images\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator( #rescale = 1./255 \n",
    "#featurewise_center=False, # set input mean to 0 over the dataset\n",
    "samplewise_center=False, # set each sample mean to 0\n",
    "#featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "samplewise_std_normalization=False, # divide each input by its std\n",
    "#zca_whitening=False, # apply ZCA whitening\n",
    "#rotation_range=1, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "#height_shift_range=0.1, # randomly shift images vertically (fraction of total height)\n",
    "#horizontal_flip=False, # randomly flip images\n",
    "vertical_flip=False) # randomly flip images\n",
    "#rescale = 1./255)\n",
    "\n",
    "td = 'Marcel-train'\n",
    "TRAIN_IMG_CNT = 4872\n",
    "#td = 'more-train'\n",
    "#TRAIN_IMG_CNT = 19488\n",
    "VALIDATION_CNT = 659\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(td, \n",
    "                                                 target_size = (64, 64), \n",
    "                                                 batch_size = batch_size,\n",
    "                                                 color_mode = 'grayscale',\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Marcel-Test', \n",
    "                                            target_size = (64, 64), \n",
    "                                            batch_size = batch_size, \n",
    "                                            color_mode = 'grayscale',\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_decay(epoch):\n",
    "\t# initialize the maximum number of epochs, base learning rate,\n",
    "\t# and power of the polynomial\n",
    "\tmaxEpochs = NUM_EPOCHS\n",
    "\tbaseLR = INIT_LR\n",
    "\tpower = 1.0\n",
    " \n",
    "\t# compute the new learning rate based on polynomial decay\n",
    "\talpha = baseLR * (1 - (epoch / float(maxEpochs))) ** power\n",
    " \n",
    "\t# return the new learning rate\n",
    "\treturn alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop_monitor = EarlyStopping(patience = 5)\n",
    "callbacks = [\n",
    "    LearningRateScheduler(poly_decay),\n",
    "#            early_stop_monitor\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 1.5534 - acc: 0.3846 - val_loss: 1.9125 - val_acc: 0.2261\n",
      "Epoch 2/100\n",
      "305/304 [==============================] - 9s 29ms/step - loss: 1.3392 - acc: 0.4508 - val_loss: 1.9543 - val_acc: 0.1836\n",
      "Epoch 3/100\n",
      "305/304 [==============================] - 9s 28ms/step - loss: 1.2720 - acc: 0.4738 - val_loss: 2.1465 - val_acc: 0.1608\n",
      "Epoch 4/100\n",
      "305/304 [==============================] - 8s 28ms/step - loss: 1.2366 - acc: 0.4799 - val_loss: 2.3919 - val_acc: 0.2322\n",
      "Epoch 5/100\n",
      "305/304 [==============================] - 9s 28ms/step - loss: 1.2248 - acc: 0.4852 - val_loss: 2.5326 - val_acc: 0.2640\n",
      "Epoch 6/100\n",
      "305/304 [==============================] - 9s 29ms/step - loss: 1.1046 - acc: 0.5305 - val_loss: 1.9249 - val_acc: 0.3111\n",
      "Epoch 7/100\n",
      "305/304 [==============================] - 9s 29ms/step - loss: 1.0311 - acc: 0.5791 - val_loss: 2.2433 - val_acc: 0.3581\n",
      "Epoch 8/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.9367 - acc: 0.6227 - val_loss: 1.7079 - val_acc: 0.4628\n",
      "Epoch 9/100\n",
      "305/304 [==============================] - 9s 30ms/step - loss: 0.8365 - acc: 0.6764 - val_loss: 1.8511 - val_acc: 0.4856\n",
      "Epoch 10/100\n",
      "305/304 [==============================] - 9s 29ms/step - loss: 0.7358 - acc: 0.7178 - val_loss: 1.7616 - val_acc: 0.5205\n",
      "Epoch 11/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.6712 - acc: 0.7461 - val_loss: 1.2987 - val_acc: 0.6100\n",
      "Epoch 12/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.6425 - acc: 0.7607 - val_loss: 1.4842 - val_acc: 0.5706\n",
      "Epoch 13/100\n",
      "305/304 [==============================] - 11s 35ms/step - loss: 0.5289 - acc: 0.8045 - val_loss: 1.1353 - val_acc: 0.6692\n",
      "Epoch 14/100\n",
      "305/304 [==============================] - 9s 30ms/step - loss: 0.4698 - acc: 0.8258 - val_loss: 1.5026 - val_acc: 0.5827\n",
      "Epoch 15/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.4595 - acc: 0.8305 - val_loss: 1.1312 - val_acc: 0.6753\n",
      "Epoch 16/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.4213 - acc: 0.8477 - val_loss: 1.4214 - val_acc: 0.6495\n",
      "Epoch 17/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.3714 - acc: 0.8590 - val_loss: 1.1888 - val_acc: 0.6161\n",
      "Epoch 18/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.3649 - acc: 0.8617 - val_loss: 1.3445 - val_acc: 0.6495\n",
      "Epoch 19/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.3376 - acc: 0.8777 - val_loss: 1.3980 - val_acc: 0.6404\n",
      "Epoch 20/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.3471 - acc: 0.8701 - val_loss: 1.3878 - val_acc: 0.6146\n",
      "Epoch 21/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.3001 - acc: 0.8900 - val_loss: 1.0975 - val_acc: 0.7178\n",
      "Epoch 22/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.2802 - acc: 0.8992 - val_loss: 1.6909 - val_acc: 0.6464\n",
      "Epoch 23/100\n",
      "305/304 [==============================] - 11s 35ms/step - loss: 0.2668 - acc: 0.9051 - val_loss: 1.2441 - val_acc: 0.6829\n",
      "Epoch 24/100\n",
      "305/304 [==============================] - 11s 36ms/step - loss: 0.2462 - acc: 0.9119 - val_loss: 1.3051 - val_acc: 0.6874\n",
      "Epoch 25/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.2578 - acc: 0.9055 - val_loss: 1.6858 - val_acc: 0.6464\n",
      "Epoch 26/100\n",
      "305/304 [==============================] - 9s 30ms/step - loss: 0.2291 - acc: 0.9195 - val_loss: 1.4265 - val_acc: 0.7132\n",
      "Epoch 27/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.2441 - acc: 0.9100 - val_loss: 1.7417 - val_acc: 0.6601\n",
      "Epoch 28/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.2181 - acc: 0.9205 - val_loss: 1.4146 - val_acc: 0.6889\n",
      "Epoch 29/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.2325 - acc: 0.9135 - val_loss: 1.1081 - val_acc: 0.7527\n",
      "Epoch 30/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.2124 - acc: 0.9230 - val_loss: 1.3898 - val_acc: 0.6920\n",
      "Epoch 31/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.2020 - acc: 0.9287 - val_loss: 1.3971 - val_acc: 0.6829\n",
      "Epoch 32/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.1911 - acc: 0.9301 - val_loss: 1.1929 - val_acc: 0.7026\n",
      "Epoch 33/100\n",
      "305/304 [==============================] - 10s 31ms/step - loss: 0.1854 - acc: 0.9303 - val_loss: 1.2496 - val_acc: 0.7178\n",
      "Epoch 34/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.1816 - acc: 0.9359 - val_loss: 1.5216 - val_acc: 0.6920\n",
      "Epoch 35/100\n",
      "305/304 [==============================] - 11s 35ms/step - loss: 0.1948 - acc: 0.9295 - val_loss: 1.1436 - val_acc: 0.7238\n",
      "Epoch 36/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.1820 - acc: 0.9328 - val_loss: 1.1722 - val_acc: 0.7238\n",
      "Epoch 37/100\n",
      "305/304 [==============================] - 10s 34ms/step - loss: 0.1618 - acc: 0.9410 - val_loss: 1.1664 - val_acc: 0.7618\n",
      "Epoch 38/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.1560 - acc: 0.9439 - val_loss: 1.4595 - val_acc: 0.6935\n",
      "Epoch 39/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.1630 - acc: 0.9398 - val_loss: 1.3091 - val_acc: 0.7329\n",
      "Epoch 40/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.1756 - acc: 0.9400 - val_loss: 1.3712 - val_acc: 0.7026\n",
      "Epoch 41/100\n",
      "305/304 [==============================] - 10s 31ms/step - loss: 0.1581 - acc: 0.9377 - val_loss: 1.8189 - val_acc: 0.6646\n",
      "Epoch 42/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.1638 - acc: 0.9426 - val_loss: 1.2044 - val_acc: 0.7451\n",
      "Epoch 43/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.1464 - acc: 0.9436 - val_loss: 1.1022 - val_acc: 0.7542\n",
      "Epoch 44/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.1443 - acc: 0.9482 - val_loss: 1.7077 - val_acc: 0.6768\n",
      "Epoch 45/100\n",
      "305/304 [==============================] - 11s 35ms/step - loss: 0.1392 - acc: 0.9477 - val_loss: 1.2714 - val_acc: 0.7284\n",
      "Epoch 46/100\n",
      "305/304 [==============================] - 10s 31ms/step - loss: 0.1529 - acc: 0.9443 - val_loss: 1.0644 - val_acc: 0.7451\n",
      "Epoch 47/100\n",
      "305/304 [==============================] - 10s 34ms/step - loss: 0.1358 - acc: 0.9518 - val_loss: 1.2671 - val_acc: 0.7238\n",
      "Epoch 48/100\n",
      "305/304 [==============================] - 10s 34ms/step - loss: 0.1422 - acc: 0.9477 - val_loss: 1.3551 - val_acc: 0.7481\n",
      "Epoch 49/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.1382 - acc: 0.9488 - val_loss: 1.6717 - val_acc: 0.7223\n",
      "Epoch 50/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.1229 - acc: 0.9537 - val_loss: 1.2492 - val_acc: 0.7618\n",
      "Epoch 51/100\n",
      "305/304 [==============================] - 10s 34ms/step - loss: 0.1208 - acc: 0.9533 - val_loss: 1.1655 - val_acc: 0.7678\n",
      "Epoch 52/100\n",
      "305/304 [==============================] - 10s 34ms/step - loss: 0.1155 - acc: 0.9561 - val_loss: 1.2263 - val_acc: 0.7451\n",
      "Epoch 53/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.1289 - acc: 0.9510 - val_loss: 1.2075 - val_acc: 0.73909 - acc:\n",
      "Epoch 54/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.1117 - acc: 0.9564 - val_loss: 1.5660 - val_acc: 0.7208\n",
      "Epoch 55/100\n",
      "305/304 [==============================] - 11s 35ms/step - loss: 0.1118 - acc: 0.9576 - val_loss: 1.2263 - val_acc: 0.7648\n",
      "Epoch 56/100\n",
      "305/304 [==============================] - 10s 34ms/step - loss: 0.1152 - acc: 0.9580 - val_loss: 1.4387 - val_acc: 0.7390\n",
      "Epoch 57/100\n",
      "305/304 [==============================] - 11s 35ms/step - loss: 0.1196 - acc: 0.9582 - val_loss: 0.9753 - val_acc: 0.7906\n",
      "Epoch 58/100\n",
      "305/304 [==============================] - 10s 34ms/step - loss: 0.1081 - acc: 0.9613 - val_loss: 1.1907 - val_acc: 0.7542\n",
      "Epoch 59/100\n",
      "305/304 [==============================] - 11s 35ms/step - loss: 0.1120 - acc: 0.9568 - val_loss: 1.2464 - val_acc: 0.7891\n",
      "Epoch 60/100\n",
      "305/304 [==============================] - 11s 35ms/step - loss: 0.1003 - acc: 0.9588 - val_loss: 1.4173 - val_acc: 0.7375\n",
      "Epoch 61/100\n",
      "305/304 [==============================] - 9s 30ms/step - loss: 0.1102 - acc: 0.9596 - val_loss: 1.2357 - val_acc: 0.7511\n",
      "Epoch 62/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.1028 - acc: 0.9611 - val_loss: 1.4944 - val_acc: 0.7314\n",
      "Epoch 63/100\n",
      "305/304 [==============================] - 10s 31ms/step - loss: 0.0892 - acc: 0.9674 - val_loss: 1.2756 - val_acc: 0.7557\n",
      "Epoch 64/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.1033 - acc: 0.9617 - val_loss: 1.6930 - val_acc: 0.7102\n",
      "Epoch 65/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.0949 - acc: 0.9623 - val_loss: 1.5703 - val_acc: 0.7238\n",
      "Epoch 66/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.0950 - acc: 0.9652 - val_loss: 1.4647 - val_acc: 0.7390\n",
      "Epoch 67/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.0980 - acc: 0.9656 - val_loss: 1.2033 - val_acc: 0.7860\n",
      "Epoch 68/100\n",
      "305/304 [==============================] - 10s 31ms/step - loss: 0.0989 - acc: 0.9641 - val_loss: 1.3072 - val_acc: 0.7344\n",
      "Epoch 69/100\n",
      "305/304 [==============================] - 10s 31ms/step - loss: 0.0926 - acc: 0.9670 - val_loss: 1.3771 - val_acc: 0.7481\n",
      "Epoch 70/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.0858 - acc: 0.9695 - val_loss: 1.3813 - val_acc: 0.7587\n",
      "Epoch 71/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.0902 - acc: 0.9678 - val_loss: 1.2057 - val_acc: 0.7800\n",
      "Epoch 72/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.0872 - acc: 0.9674 - val_loss: 1.1530 - val_acc: 0.7678\n",
      "Epoch 73/100\n",
      "305/304 [==============================] - 10s 31ms/step - loss: 0.0822 - acc: 0.9666 - val_loss: 1.2194 - val_acc: 0.7739\n",
      "Epoch 74/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.0931 - acc: 0.9672 - val_loss: 1.4934 - val_acc: 0.7527\n",
      "Epoch 75/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.0817 - acc: 0.9703 - val_loss: 1.5070 - val_acc: 0.7299\n",
      "Epoch 76/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.0894 - acc: 0.9660 - val_loss: 1.3362 - val_acc: 0.7405\n",
      "Epoch 77/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.0853 - acc: 0.9674 - val_loss: 1.3130 - val_acc: 0.7557\n",
      "Epoch 78/100\n",
      "305/304 [==============================] - 10s 31ms/step - loss: 0.0806 - acc: 0.9701 - val_loss: 1.6004 - val_acc: 0.7284\n",
      "Epoch 79/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.0777 - acc: 0.9697 - val_loss: 1.3173 - val_acc: 0.7769\n",
      "Epoch 80/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.0768 - acc: 0.9707 - val_loss: 1.4759 - val_acc: 0.7360\n",
      "Epoch 81/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.0779 - acc: 0.9723 - val_loss: 1.4579 - val_acc: 0.7420\n",
      "Epoch 82/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.0792 - acc: 0.9711 - val_loss: 1.6558 - val_acc: 0.7253\n",
      "Epoch 83/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.0824 - acc: 0.9666 - val_loss: 1.4537 - val_acc: 0.7511\n",
      "Epoch 84/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.0788 - acc: 0.9693 - val_loss: 1.6061 - val_acc: 0.7375\n",
      "Epoch 85/100\n",
      "305/304 [==============================] - 10s 31ms/step - loss: 0.0736 - acc: 0.9721 - val_loss: 1.4880 - val_acc: 0.7587\n",
      "Epoch 86/100\n",
      "305/304 [==============================] - 10s 31ms/step - loss: 0.0740 - acc: 0.9707 - val_loss: 1.5433 - val_acc: 0.7375\n",
      "Epoch 87/100\n",
      "305/304 [==============================] - 9s 31ms/step - loss: 0.0742 - acc: 0.9727 - val_loss: 1.6606 - val_acc: 0.7253\n",
      "Epoch 88/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.0716 - acc: 0.9715 - val_loss: 1.4120 - val_acc: 0.7618\n",
      "Epoch 89/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.0773 - acc: 0.9721 - val_loss: 1.4139 - val_acc: 0.7602\n",
      "Epoch 90/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.0687 - acc: 0.9742 - val_loss: 1.4170 - val_acc: 0.7557\n",
      "Epoch 91/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.0743 - acc: 0.9736 - val_loss: 1.3238 - val_acc: 0.7754\n",
      "Epoch 92/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.0737 - acc: 0.9713 - val_loss: 1.4556 - val_acc: 0.7557\n",
      "Epoch 93/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.0789 - acc: 0.9721 - val_loss: 1.4525 - val_acc: 0.7451\n",
      "Epoch 94/100\n",
      "305/304 [==============================] - 10s 32ms/step - loss: 0.0664 - acc: 0.9742 - val_loss: 1.5095 - val_acc: 0.7329\n",
      "Epoch 95/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.0744 - acc: 0.9721 - val_loss: 1.4269 - val_acc: 0.7542\n",
      "Epoch 96/100\n",
      "305/304 [==============================] - 11s 35ms/step - loss: 0.0697 - acc: 0.9734 - val_loss: 1.6327 - val_acc: 0.7238\n",
      "Epoch 97/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.0710 - acc: 0.9746 - val_loss: 1.6378 - val_acc: 0.7269\n",
      "Epoch 98/100\n",
      "305/304 [==============================] - 10s 34ms/step - loss: 0.0698 - acc: 0.9748 - val_loss: 1.5895 - val_acc: 0.7329\n",
      "Epoch 99/100\n",
      "305/304 [==============================] - 10s 33ms/step - loss: 0.0623 - acc: 0.9768 - val_loss: 1.6094 - val_acc: 0.7344\n",
      "Epoch 100/100\n",
      "305/304 [==============================] - 10s 34ms/step - loss: 0.0727 - acc: 0.9721 - val_loss: 1.5964 - val_acc: 0.7375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit_generator(training_set, steps_per_epoch = TRAIN_IMG_CNT / batch_size, epochs = NUM_EPOCHS,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data = test_set, validation_steps = VALIDATION_CNT / batch_size)\n",
    "model.save_weights('1st_run.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
